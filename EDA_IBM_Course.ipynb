{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShubhamPrakash108/DogVsCat_Classifier/blob/main/EDA_IBM_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzL2PssH6iU9"
      },
      "source": [
        "Link:- https://www.kaggle.com/competitions/playground-series-s4e7/code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASOPJTED6Ypw",
        "outputId": "adfe2926-72bf-4f40-f3d8-70253a42e426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading playground-series-s4e7, 259402906 bytes compressed\n",
            "[==================================================] 259402906 bytes downloaded\n",
            "Downloaded and uncompressed: playground-series-s4e7\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'playground-series-s4e7:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F73291%2F8930475%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240724%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240724T084340Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D474db68bd0d22ad8d9447f43ae708725c752382b91d32ac58c4709e646df0940b98c2ee4a1fd4c53afbd1b26d31e9b88d20f82717924571a10d2dcb98f437febe47ff0c00b8b68bc393d97a907fce20cdaabd1fd06ef659a127fc878ce9c00a7d9cc8df2893786a63c636c924ed384f961757931e039ec11a129f698fb65f520d61fa4551037591e65cd87d4bfd320f2e7c350886341bf75f7da68d757b6b4dc9eea5645dc53793c7c38ff1c550b15cebd5acedf6ad3ae0d5c73d2da52f4b37ddc99276162d40dd6d718298753888b52e27ccbc26e6c47ef8c91ccf22477c9e49248757090fa50eff6b9e3fd3cc2b9f59531dfe176ea0ade060b3d219ab9f5ce'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phzLRssO6Ypy",
        "outputId": "7a86709a-d829-4dec-c041-decb90eedd48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/playground-series-s4e7/sample_submission.csv\n",
            "/kaggle/input/playground-series-s4e7/test.csv\n",
            "/kaggle/input/playground-series-s4e7/train.csv\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlhjKZ01DMJ5"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "c-whzaONDqDE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import scipy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3ky4DJ0J6uks",
        "outputId": "71ab9d40-69eb-4cc4-a8e3-b290f4f283e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
              "0   0    Male   21                1         35.0                   0   \n",
              "1   1    Male   43                1         28.0                   0   \n",
              "2   2  Female   25                1         14.0                   1   \n",
              "3   3  Female   35                1          1.0                   0   \n",
              "4   4  Female   36                1         15.0                   1   \n",
              "\n",
              "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
              "0    1-2 Year            Yes         65101.0                 124.0      187   \n",
              "1   > 2 Years            Yes         58911.0                  26.0      288   \n",
              "2    < 1 Year             No         38043.0                 152.0      254   \n",
              "3    1-2 Year            Yes          2630.0                 156.0       76   \n",
              "4    1-2 Year             No         31951.0                 152.0      294   \n",
              "\n",
              "   Response  \n",
              "0         0  \n",
              "1         1  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1291c9ca-787e-4a3a-976d-25ce24bb0771\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Driving_License</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Previously_Insured</th>\n",
              "      <th>Vehicle_Age</th>\n",
              "      <th>Vehicle_Damage</th>\n",
              "      <th>Annual_Premium</th>\n",
              "      <th>Policy_Sales_Channel</th>\n",
              "      <th>Vintage</th>\n",
              "      <th>Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Male</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1-2 Year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>65101.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>&gt; 2 Years</td>\n",
              "      <td>Yes</td>\n",
              "      <td>58911.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>288</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Female</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt; 1 Year</td>\n",
              "      <td>No</td>\n",
              "      <td>38043.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1-2 Year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2630.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1-2 Year</td>\n",
              "      <td>No</td>\n",
              "      <td>31951.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>294</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1291c9ca-787e-4a3a-976d-25ce24bb0771')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1291c9ca-787e-4a3a-976d-25ce24bb0771 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1291c9ca-787e-4a3a-976d-25ce24bb0771');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c09160bc-a3dd-4e7e-ad7b-fd653e9341b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c09160bc-a3dd-4e7e-ad7b-fd653e9341b1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c09160bc-a3dd-4e7e-ad7b-fd653e9341b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "data = pd.read_csv(\"/kaggle/input/playground-series-s4e7/train.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#There is no use of Id for this problem\n",
        "data.drop('id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "q7NXVY1jOJjp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZIfDDek9lJ7"
      },
      "source": [
        "##EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZABXa_29Zks"
      },
      "source": [
        "#####Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HH9KkWz8pB-"
      },
      "source": [
        "Cleaning the data is important:\n",
        "Good data = Good results.\n",
        "I am going to identify duplicate or unnecessary data and I will also be dealing with the outliers.\n",
        "\n",
        "How can data be messy?\n",
        "1. Duplicate and Missing data\n",
        "2. Unnecessary data, inconsistent text and typos\n",
        "3. Outliers( it skews the data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebN8EjAH-4k2"
      },
      "source": [
        "Policies for Missing data\n",
        "1. When we talk about removing the data as a method for handling missing values, it means that we choose to eliminate the entire row of data that contains the missing value. This approach is often used when we believe that the missing values are random and do not carry any significant information.\n",
        "\n",
        "Here are the key points to consider when removing the data:\n",
        "\n",
        "Pros:\n",
        "\n",
        "Quick and straightforward: Removing the entire row with missing values can quickly clean up the dataset without the need to guess or estimate replacement values.\n",
        "Minimal impact: If the missing values are only present in a small number of rows, removing those rows may not have a significant impact on the overall dataset.\n",
        "Cons:\n",
        "\n",
        "Loss of information: By removing rows with missing values, we may lose valuable information that could be important for our analysis or modeling.\n",
        "Potential bias: If certain columns have missing values for many rows, removing those rows may introduce bias into the dataset, as the missing values may be related to a specific reason or condition.\n",
        "It's important to carefully consider the pros and cons of removing data with missing values in order to make an informed decision. If the missing values are minimal and randomly distributed, removing the data may be a viable option. However, if the missing values are substantial or potentially carry important information, alternative methods such as imputation or masking may be more appropriate.\n",
        "\n",
        "2. Imputing the data is another method for handling missing values in a dataset. Instead of removing the rows with missing values, we replace those missing values with estimated values based on the available data.\n",
        "\n",
        "Here are the key points to understand about imputing the data:\n",
        "\n",
        "Pros:\n",
        "\n",
        "Retains information: Imputing the missing values allows us to keep the entire dataset intact, including the rows and columns that may contain valuable information for our analysis or modeling.\n",
        "Preserves sample size: By imputing the missing values, we can maintain the original sample size, which can be important for statistical analysis and modeling.\n",
        "Flexibility in estimation: We can choose different methods for imputing the missing values, such as using the mean, median, or more complex estimation techniques. This flexibility allows us to tailor the imputation method to the specific characteristics of the dataset.\n",
        "Cons:\n",
        "\n",
        "Introduction of uncertainty: Imputing missing values introduces an additional level of uncertainty, as the imputed values are estimates rather than actual observed values. This uncertainty can affect the accuracy and reliability of our analysis or modeling.\n",
        "Potential bias: Depending on the imputation method used, there is a risk of introducing bias into the dataset. The imputed values may not accurately represent the true values of the missing data, which can impact the validity of our results.\n",
        "\n",
        "3. Mask the data: Masking the data is another approach for handling missing values in a dataset. Instead of removing or imputing the missing values, we treat them as a separate category or indicator, indicating that the value is missing.\n",
        "\n",
        "Here are the key points to understand about masking the data:\n",
        "\n",
        "Pros:\n",
        "\n",
        "Retains information: Masking the missing values allows us to keep the entire dataset intact, including the rows and columns that may contain valuable information for our analysis or modeling.\n",
        "Preserves sample size: By masking the missing values, we can maintain the original sample size, which can be important for statistical analysis and modeling.\n",
        "Potential insights: Treating missing values as a separate category assumes that the missingness itself carries useful information. In some cases, missing values may indicate patterns or reasons that can provide insights into the data.\n",
        "Cons:\n",
        "\n",
        "Introduction of uncertainty: Masking the missing values introduces an additional level of uncertainty, as we are treating the missing values as a distinct category. This uncertainty can affect the accuracy and reliability of our analysis or modeling.\n",
        "Assumption of similarity: Treating all missing values as alike assumes that they have a common reason for being missing. This assumption may not always hold true, and it can lead to biased results if the missing values are not truly similar.\n",
        "When considering masking the data, it is important to carefully evaluate whether missing values carry meaningful information and whether treating them as a separate category aligns with the goals of the analysis. This approach can be useful when missing values are not extensive and when there is a reasonable assumption that the missingness itself is informative.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjcoQ6_M_06T"
      },
      "source": [
        "Outliers: Outliers are observations in a dataset that significantly deviate from the majority of the data points. These observations are distinct and can have a substantial impact on the analysis or modeling process. Here are the key points to understand about outliers:\n",
        "\n",
        "Definition: Outliers are data points that are located far away from the central tendency of the dataset. They can be unusually high or low values compared to the rest of the data.\n",
        "Impact on analysis: Outliers can have a significant impact on statistical analysis and modeling. They can skew the results, affect the accuracy of predictions, and distort the overall patterns and relationships in the data.\n",
        "Identification: Outliers can be identified through various methods, such as visual inspection of plots like histograms, density plots, and box plots. They can also be detected using mathematical calculations, such as percentiles and interquartile range.\n",
        "Interpretation: It is important to interpret outliers carefully. While some outliers may be data errors or anomalies that need to be addressed, others may provide valuable insights into the data. Outliers can indicate rare events, extreme conditions, or unusual patterns that are worth investigating further.\n",
        "Handling outliers: The approach to handling outliers depends on the specific context and goals of the analysis. In some cases, outliers may be removed if they are deemed as data errors. However, it is crucial to exercise caution when removing outliers, as they may contain valuable information. Alternatively, outliers can be transformed or adjusted to reduce their impact on the analysis.\n",
        "Overall, outliers should be carefully examined and considered in the analysis process. They can provide valuable insights or introduce biases, depending on the context. It is important to strike a balance between addressing outliers that are detrimental to the analysis and preserving outliers that carry meaningful information.\n",
        "\n",
        "\n",
        "________________________________________________________________________________\n",
        "Residuals are the differences between the actual values and the predicted values of a model. They represent the model's failure to accurately predict the outcome. Residuals are an important concept in exploratory data analysis for machine learning because they can be used to detect outliers and assess the performance of the model.\n",
        "\n",
        "There are different approaches to leverage residuals for outlier detection:\n",
        "\n",
        "Standardized Residuals: These are obtained by dividing the residual by the standard error. Standardizing the residuals allows for comparison across different outcome variable ranges.\n",
        "\n",
        "Deleted Residuals: In this approach, an observation is removed from the dataset, and the model is retrained without that observation. The difference between the original model's prediction and the prediction with the deleted observation can help identify outliers.\n",
        "\n",
        "Studentized Residuals: Similar to deleted residuals, studentized residuals involve removing one observation at a time and standardizing the residuals based on the range of the model. This approach helps assess the impact of each observation on the model.\n",
        "Once an outlier is detected using residuals, there are several ways to handle it:\n",
        "\n",
        "Remove the outlier altogether: This eliminates the outlier's effect on the model, but it may result in the loss of important information.\n",
        "Assign a different value to the outlier: By replacing the outlier with a different value, you can mitigate its impact on the model while retaining the rest of the row.\n",
        "Transform the column with the outlier: Applying a transformation, such as a log transformation, to the column containing the outlier may change its range and make it no longer an outlier.\n",
        "Predict the value of the outlier: This can be done by using similar observations or regression techniques to estimate what the value would have been if it were not an outlier.\n",
        "Keep the outlier: If you are using a model that is resistant to outliers, you may choose to keep the outlier and account for its influence in the analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz4tUKOg8YsM",
        "outputId": "6ebf2ed4-8366-4df3-f34e-3fb9340973e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11504798 entries, 0 to 11504797\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Dtype  \n",
            "---  ------                -----  \n",
            " 0   Gender                object \n",
            " 1   Age                   int64  \n",
            " 2   Driving_License       int64  \n",
            " 3   Region_Code           float64\n",
            " 4   Previously_Insured    int64  \n",
            " 5   Vehicle_Age           object \n",
            " 6   Vehicle_Damage        object \n",
            " 7   Annual_Premium        float64\n",
            " 8   Policy_Sales_Channel  float64\n",
            " 9   Vintage               int64  \n",
            " 10  Response              int64  \n",
            "dtypes: float64(3), int64(5), object(3)\n",
            "memory usage: 965.5+ MB\n"
          ]
        }
      ],
      "source": [
        "# Getting the overview of the data\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGg5zQACDzAA",
        "outputId": "6e9b4e6a-07e8-474d-89ec-dccbcdd47e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    1.150480e+07\n",
            "mean     3.838356e+01\n",
            "std      1.499346e+01\n",
            "min      2.000000e+01\n",
            "25%      2.400000e+01\n",
            "50%      3.600000e+01\n",
            "75%      4.900000e+01\n",
            "max      8.500000e+01\n",
            "Name: Age, dtype: float64\n",
            "count    1.150480e+07\n",
            "mean     9.980220e-01\n",
            "std      4.443120e-02\n",
            "min      0.000000e+00\n",
            "25%      1.000000e+00\n",
            "50%      1.000000e+00\n",
            "75%      1.000000e+00\n",
            "max      1.000000e+00\n",
            "Name: Driving_License, dtype: float64\n",
            "count    1.150480e+07\n",
            "mean     2.641869e+01\n",
            "std      1.299159e+01\n",
            "min      0.000000e+00\n",
            "25%      1.500000e+01\n",
            "50%      2.800000e+01\n",
            "75%      3.500000e+01\n",
            "max      5.200000e+01\n",
            "Name: Region_Code, dtype: float64\n",
            "count    1.150480e+07\n",
            "mean     4.629966e-01\n",
            "std      4.986289e-01\n",
            "min      0.000000e+00\n",
            "25%      0.000000e+00\n",
            "50%      0.000000e+00\n",
            "75%      1.000000e+00\n",
            "max      1.000000e+00\n",
            "Name: Previously_Insured, dtype: float64\n",
            "count    1.150480e+07\n",
            "mean     3.046137e+04\n",
            "std      1.645475e+04\n",
            "min      2.630000e+03\n",
            "25%      2.527700e+04\n",
            "50%      3.182400e+04\n",
            "75%      3.945100e+04\n",
            "max      5.401650e+05\n",
            "Name: Annual_Premium, dtype: float64\n",
            "count    1.150480e+07\n",
            "mean     1.124254e+02\n",
            "std      5.403571e+01\n",
            "min      1.000000e+00\n",
            "25%      2.900000e+01\n",
            "50%      1.510000e+02\n",
            "75%      1.520000e+02\n",
            "max      1.630000e+02\n",
            "Name: Policy_Sales_Channel, dtype: float64\n",
            "count    1.150480e+07\n",
            "mean     1.638977e+02\n",
            "std      7.997953e+01\n",
            "min      1.000000e+01\n",
            "25%      9.900000e+01\n",
            "50%      1.660000e+02\n",
            "75%      2.320000e+02\n",
            "max      2.990000e+02\n",
            "Name: Vintage, dtype: float64\n",
            "count    1.150480e+07\n",
            "mean     1.229973e-01\n",
            "std      3.284341e-01\n",
            "min      0.000000e+00\n",
            "25%      0.000000e+00\n",
            "50%      0.000000e+00\n",
            "75%      0.000000e+00\n",
            "max      1.000000e+00\n",
            "Name: Response, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Getting the standard mathematical insights of the numerical data\n",
        "for col in data.columns:\n",
        "  if data[col].dtype != 'object':\n",
        "    print(data[col].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbSgTOe7EGJd",
        "outputId": "b9a37937-a0e4-484e-a3b3-75531b9347b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender : Gender\n",
            "Male      6228134\n",
            "Female    5276664\n",
            "Name: count, dtype: int64\n",
            "Driving_License : Driving_License\n",
            "1    11482041\n",
            "0       22757\n",
            "Name: count, dtype: int64\n",
            "Previously_Insured : Previously_Insured\n",
            "0    6178116\n",
            "1    5326682\n",
            "Name: count, dtype: int64\n",
            "Vehicle_Age : Vehicle_Age\n",
            "1-2 Year     5982678\n",
            "< 1 Year     5044145\n",
            "> 2 Years     477975\n",
            "Name: count, dtype: int64\n",
            "Vehicle_Damage : Vehicle_Damage\n",
            "Yes    5783229\n",
            "No     5721569\n",
            "Name: count, dtype: int64\n",
            "Response : Response\n",
            "0    10089739\n",
            "1     1415059\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking the categorical columns in the dataset\n",
        "for col in data.columns:\n",
        "  if data[col].value_counts().size < 7 :\n",
        "    print(f\"{col} : {data[col].value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u1qdLukjIJuM",
        "outputId": "4fc5f586-2b49-4b05-8a8b-900ba4433f16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Gender  Age  Driving_License  Region_Code  Previously_Insured Vehicle_Age  \\\n",
              "0    Male   21                1         35.0                   0    1-2 Year   \n",
              "1    Male   43                1         28.0                   0   > 2 Years   \n",
              "2  Female   25                1         14.0                   1    < 1 Year   \n",
              "3  Female   35                1          1.0                   0    1-2 Year   \n",
              "4  Female   36                1         15.0                   1    1-2 Year   \n",
              "\n",
              "  Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  Response  \n",
              "0            Yes         65101.0                 124.0      187         0  \n",
              "1            Yes         58911.0                  26.0      288         1  \n",
              "2             No         38043.0                 152.0      254         0  \n",
              "3            Yes          2630.0                 156.0       76         0  \n",
              "4             No         31951.0                 152.0      294         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88b11b7a-a698-4e26-8c86-e7955b63204a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Driving_License</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Previously_Insured</th>\n",
              "      <th>Vehicle_Age</th>\n",
              "      <th>Vehicle_Damage</th>\n",
              "      <th>Annual_Premium</th>\n",
              "      <th>Policy_Sales_Channel</th>\n",
              "      <th>Vintage</th>\n",
              "      <th>Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Male</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1-2 Year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>65101.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>&gt; 2 Years</td>\n",
              "      <td>Yes</td>\n",
              "      <td>58911.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>288</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Female</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt; 1 Year</td>\n",
              "      <td>No</td>\n",
              "      <td>38043.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1-2 Year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2630.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1-2 Year</td>\n",
              "      <td>No</td>\n",
              "      <td>31951.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>294</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88b11b7a-a698-4e26-8c86-e7955b63204a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88b11b7a-a698-4e26-8c86-e7955b63204a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88b11b7a-a698-4e26-8c86-e7955b63204a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5120c502-4386-4fd4-aa68-51da6bdcad95\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5120c502-4386-4fd4-aa68-51da6bdcad95')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5120c502-4386-4fd4-aa68-51da6bdcad95 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8yamJQ_FsQN",
        "outputId": "6d50c522-3bb9-4ed7-b2ad-caaf9b652188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is 1 strongly correlated values with SalePrice:\n",
            "Previously_Insured   -0.34593\n",
            "Name: Response, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#Finding the correlation of Response with others\n",
        "data_num = data.select_dtypes(include = ['float64', 'int64'])\n",
        "data_response = data_num.corr()['Response'][:-1]\n",
        "top_features = data_response[abs(data_response) > 0.3].sort_values(ascending=False)\n",
        "print(\"There is {} strongly correlated values with SalePrice:\\n{}\".format(len(top_features), top_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYlO457adWAm"
      },
      "outputs": [],
      "source": [
        "#Generating the correlation graph using seaborn\n",
        "for i in range(0, len(data.columns), 5):\n",
        "    sns.pairplot(data=data,\n",
        "                x_vars=data.columns[i:i+5],\n",
        "                y_vars=['Response'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_GG9p_jjYyP"
      },
      "source": [
        "###########Edit\n",
        "Looking for Correlations¶\n",
        "Before proceeding with the data cleaning, it is useful to establish a correlation between the response variable (in our case the sale price) and other predictor variables, as some of them might not have any major impact in determining the price of the house and will not be used in the analysis. There are many ways to discover correlation between the target variable and the rest of the features. Building pair plots, scatter plots, heat maps, and a correlation matrixes are the most common ones. Below, we will use the corr() function to list the top features based on the pearson correlation coefficient (measures how closely two sequences of numbers are correlated). Correlation coefficient can only be calculated on the numerical attributes (floats and integers), therefore, only the numeric attributes will be selected.\n",
        "\n",
        "\n",
        "\n",
        "The range of skewness for a fairly symmetrical bell curve distribution is between -0.5 and 0.5; moderate skewness is -0.5 to -1.0 and 0.5 to 1.0; and highly skewed distribution is < -1.0 and > 1.0. In our case, we have ~1.7, so it is considered highly skewed data.\n",
        "\n",
        "Now, we can try to transform our data, so it looks more normally distributed. We can use the np.log() function from the numpy library to perform log transform. This documentation contains more information about the numpy log transform.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnA-tCtHeBQ0"
      },
      "outputs": [],
      "source": [
        "# Checking wether the data is normally distributed or not by using Log Transform\n",
        "sp_untransformed = sns.displot(data['Age'], height=5, aspect=1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APdDUy__k1m1"
      },
      "outputs": [],
      "source": [
        "print(\"Skewness: %f\" % data['Age'].skew())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRdqSEEKodEL"
      },
      "source": [
        "Now, we can try to transform our data, so it looks more normally distributed. We can use the np.log() function from the numpy library to perform log transform. This documentation contains more information about the numpy log transform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoL55i3yqJ-k"
      },
      "outputs": [],
      "source": [
        "log_transformed = np.log(data['Age'])\n",
        "sp_transformed = sns.displot(log_transformed)\n",
        "print(\"Skewness: %f\" % (log_transformed).skew())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb8j8YBwqXf0"
      },
      "outputs": [],
      "source": [
        "#Lets see whether there are some duplicates or not\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXSNh3TqrYfa"
      },
      "source": [
        "Finding the Missing Values\n",
        "For easier detection of missing values, pandas provides the isna(), isnull(), and notna() functions. For more information on pandas missing values please check out this documentation.\n",
        "\n",
        "To summarize all the missing values in our dataset, we will use isnull() function. Then, we will add them all up, by using sum() function, sort them with sort_values() function, and plot the first 20 columns (as the majority of our missing values fall within first 20 columns), using the bar plot function from the matplotlib library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0uRvtKztCs7"
      },
      "outputs": [],
      "source": [
        "#Handling the missing values(if any)\n",
        "total = data.isnull().sum().sort_values(ascending=False)\n",
        "total_select = total.head(20)\n",
        "total_select.plot(kind=\"bar\", figsize = (8,6), fontsize = 10)\n",
        "\n",
        "plt.xlabel(\"Columns\", fontsize = 20)\n",
        "plt.ylabel(\"Count\", fontsize = 20)\n",
        "plt.title(\"Total Missing Values\", fontsize = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MxeARiltfDM"
      },
      "source": [
        "So, there is no missing values\n",
        "\n",
        "There are several options for dealing with missing values. We will use 'Lot Frontage' feature to analyze for missing values.\n",
        "\n",
        "We can drop the missing values, using dropna() method.\n",
        "housing.dropna(subset=[\"Lot Frontage\"])\n",
        "Using this method, all the rows, containing null values in 'Lot Frontage' feature, for example, will be dropped.\n",
        "\n",
        "We can drop the whole attribute (column), that contains missing values, using the drop() method.\n",
        "housing.drop(\"Lot Frontage\", axis=1)\n",
        "Using this method, the entire column containing the null values will be dropped.\n",
        "\n",
        "We can replace the missing values (zero, the mean, the median, etc.), using fillna() method.\n",
        "median = housing[\"Lot Frontage\"].median()\n",
        "median\n",
        "housing[\"Lot Frontage\"].fillna(median, inplace = True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPrQXJAixHj8"
      },
      "source": [
        "_______________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikGvvt-ixD7u"
      },
      "source": [
        "Feature Scaling One of the most important transformations we need to apply to our data is feature scaling. There are two common ways to get all attributes to have the same scale: min-max scaling and standardization.\n",
        "\n",
        "Min-max scaling (or normalization) is the simplest: values are shifted and rescaled so they end up ranging from 0 to 1. This is done by subtracting the min value and dividing by the max minus min.\n",
        "\n",
        "Standardization is different: first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation, so that the resulting distribution has unit variance.\n",
        "\n",
        "Scikit-learn library provides MinMaxScaler for normalization and StandardScaler for standardization needs. For more information on scikit-learn MinMaxScaler and StandardScaler please visit their respective documentation websites.\n",
        "\n",
        "First, we will normalize our data.\n",
        "\n",
        "norm_data = MinMaxScaler().fit_transform(hous_num) norm_data Note the data is now a ndarray\n",
        "\n",
        "we can also standardize our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCnV7vcltq78"
      },
      "outputs": [],
      "source": [
        "#do after changing the data into numbers\n",
        "norm_data = MinMaxScaler().fit_transform(data[\"Age\"])\n",
        "norm_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqGWz9rWxOeL"
      },
      "source": [
        "Handling the Outliers¶\n",
        "Finding the Outliers\n",
        "In statistics, an outlier is an observation point that is distant from other observations. An outlier can be due to some mistakes in data collection or recording, or due to natural high variability of data points. How to treat an outlier highly depends on our data or the type of analysis to be performed. Outliers can markedly affect our models and can be a valuable source of information, providing us insights about specific behaviours.\n",
        "\n",
        "There are many ways to discover outliers in our data. We can do Uni-variate analysis (using one variable analysis) or Multi-variate analysis (using two or more variables). One of the simplest ways to detect an outlier is to inspect the data visually, by making box plots or scatter plots.\n",
        "\n",
        "Uni-variate Analysis\n",
        "A box plot is a method for graphically depicting groups of numerical data through their quartiles. Box plots may also have lines extending vertically from the boxes (whiskers) indicating variability outside the upper and lower quartiles. Outliers may be plotted as individual points. To learn more about box plots please click here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7TnzDddx_AQ"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data['Normalized_Age'] = MinMaxScaler().fit_transform(data[['Age']])\n",
        "\n",
        "sns.boxplot(data=data.drop(['Region_Code'], axis=1), x='Normalized_Age', orient='h')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAI9HgITyFSm"
      },
      "source": [
        "As we can see from these two plots, we have some points that are plotted outside the box plot area and that greatly deviate from the rest of the population. Whether to remove or keep them will greatly depend on the understanding of our data and the type of analysis to be performed. In this case, the points that are outside of our box plots in the 'Lot Area' and the 'Sale Price' might be the actual true data points and do not need to be removed.\n",
        "\n",
        "Bi-variate Analysis\n",
        "Next, we will look at the bi-variate analysis of the two features, the sale price, 'SalePrice', and the ground living area, 'GrLivArea', and plot the scatter plot of the relationship between these two parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJFz0xVwyRfO"
      },
      "outputs": [],
      "source": [
        "price_area = data.plot.scatter(x='Annual_Premium',\n",
        "                      y='Age')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure! Let's dive into how to use various data visualization libraries in Python, specifically focusing on Matplotlib, Pandas, and Seaborn. We will go through some practical examples with code snippets to illustrate their usage.\n",
        "\n",
        "### Data Visualization Libraries in Python\n",
        "\n",
        "1. **Matplotlib**:\n",
        "   - A foundational plotting library in Python.\n",
        "   - Highly customizable with a variety of plotting options.\n",
        "\n",
        "2. **Pandas**:\n",
        "   - Offers convenient plotting capabilities through a wrapper around Matplotlib.\n",
        "   - Less flexible than Matplotlib but easier and quicker for simple plots.\n",
        "\n",
        "3. **Seaborn**:\n",
        "   - Built on top of Matplotlib.\n",
        "   - Provides high-level interfaces for drawing attractive statistical graphics.\n",
        "\n",
        "### Example 1: Scatter Plot with Matplotlib\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Let's assume we have a DataFrame 'df' with columns 'sepal_length' and 'sepal_width'.\n",
        "df = ...  # Your DataFrame here\n",
        "\n",
        "# Basic scatter plot\n",
        "plt.scatter(df['sepal_length'], df['sepal_width'], marker='o')\n",
        "plt.xlabel('Sepal Length')\n",
        "plt.ylabel('Sepal Width')\n",
        "plt.title('Scatter Plot of Sepal Length vs Sepal Width')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Example 2: Multiple Layers in Scatter Plot\n",
        "\n",
        "```python\n",
        "# Adding another layer to the scatter plot\n",
        "plt.scatter(df['sepal_length'], df['sepal_width'], marker='o', label='Sepal')\n",
        "plt.scatter(df['petal_length'], df['petal_width'], marker='x', label='Petal')\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('Width')\n",
        "plt.title('Scatter Plot of Sepal and Petal Dimensions')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Example 3: Histogram with Matplotlib\n",
        "\n",
        "```python\n",
        "# Histogram of 'sepal_length'\n",
        "plt.hist(df['sepal_length'], bins=20)\n",
        "plt.xlabel('Sepal Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Sepal Length')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Example 4: Object-Oriented Interface in Matplotlib\n",
        "\n",
        "```python\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(df['sepal_length'][:10], df['sepal_width'][:10])\n",
        "ax.set_xlabel('Sepal Length')\n",
        "ax.set_ylabel('Sepal Width')\n",
        "ax.set_title('Bar Plot of Sepal Dimensions')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Example 5: Plotting with Pandas\n",
        "\n",
        "```python\n",
        "# Group by 'species' and plot mean values\n",
        "grouped = df.groupby('species').mean()\n",
        "grouped.plot(kind='line', figsize=(8, 6), fontsize=10, colormap='viridis')\n",
        "plt.xlabel('Species')\n",
        "plt.ylabel('Mean Values')\n",
        "plt.title('Mean Sepal and Petal Dimensions by Species')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Example 6: Pair Plot with Seaborn\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "\n",
        "# Pair plot to show relationships between all pairs of features\n",
        "sns.pairplot(df, hue='species', height=2.5)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Example 7: Hexbin Plot with Seaborn\n",
        "\n",
        "```python\n",
        "# Joint plot with hexbin\n",
        "sns.jointplot(x='sepal_length', y='sepal_width', data=df, kind='hex', gridsize=20)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Example 8: Facet Grid with Seaborn\n",
        "\n",
        "```python\n",
        "# Facet grid to plot histograms for each species\n",
        "g = sns.FacetGrid(df, col='species')\n",
        "g.map(plt.hist, 'sepal_length')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Recap\n",
        "\n",
        "- **Matplotlib**: Highly flexible, powerful for detailed customization.\n",
        "- **Pandas**: Convenient for quick plots directly from DataFrames.\n",
        "- **Seaborn**: Great for statistically informative and visually appealing plots.\n",
        "\n",
        "In practice, you might start with Pandas for quick insights, use Matplotlib for detailed and custom visualizations, and leverage Seaborn for advanced statistical graphics."
      ],
      "metadata": {
        "id": "1EiqAw83mZeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "b1VXKkUxJj5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['agg.path.chunksize'] = 10000\n",
        "\n",
        "# Now try your plotting code again, for example:\n",
        "plt.plot(data['Age'], data['Response'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yk14WYsy_vTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a summary of the codes discussed:\n",
        "\n",
        "Grouping and Plotting with Pandas:\n",
        "\n",
        "Grouping the data frame by a specific column using the groupby() function.\n",
        "Calculating the mean for each feature using the mean() function.\n",
        "Plotting the grouped data using the plot() function.\n",
        "Setting line style to blank to remove lines from the plot.\n",
        "Setting specific colors for each feature using the color parameter.\n",
        "Setting font size and figure size using the fontsize and figsize parameters.\n",
        "Pair Plotting with Seaborn:\n",
        "\n",
        "Importing the Seaborn library using import seaborn as sns.\n",
        "Using the pairplot() function to create scatter plots between each feature.\n",
        "Setting the hue parameter to break down the plot by color.\n",
        "Setting the size parameter to define the size of the plot.\n",
        "Visualizing correlations and histograms across all columns.\n",
        "Hex Bin Plotting with Seaborn:\n",
        "\n",
        "Using the jointplot() function to create a hex bin plot.\n",
        "Specifying the x and y values for the plot.\n",
        "Showing the density of similar points using hexagons.\n",
        "Displaying histograms of the x and y values.\n",
        "Facet Grid Plotting with Seaborn:\n",
        "Using the FacetGrid() function to create a grid of subplots.\n",
        "Specifying the data and column arguments.\n",
        "Setting margin_titles to True to add titles to each subplot.\n",
        "Mapping a histogram to each subplot using the map() function.\n",
        "These codes demonstrate how to perform exploratory data analysis and create various visualizations using Pandas and Seaborn libraries."
      ],
      "metadata": {
        "id": "_VgFKqr3LcZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data, hue='Response',height=3)"
      ],
      "metadata": {
        "id": "U3l1y0fkJps4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use .str.replace('Iris','') to replace the string 'Iris' with an empty string. Lambda function can also be used."
      ],
      "metadata": {
        "id": "ApANyZIILlxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering:  Feature engineering involves encoding categorical data and transforming variables to ensure a linear relationship. We will also discuss feature scaling, which is important for many machine learning algorithms. The section will provide a foundation for understanding linear regression and its assumptions. Overall, this section will help you prepare your data for modeling and improve the performance of your machine learning algorithms.\n",
        "\n",
        "\n",
        "\n",
        "Revise : Polynomial Features [link](https://www.coursera.org/learn/ibm-exploratory-data-analysis-for-machine-learning/lecture/K4120/variable-transformation)\n",
        "\n",
        "\n",
        "Here's a summary of the key points about variable selection and transformation in data modeling:\n",
        "\n",
        "1. Variable selection involves choosing which features to include in a model.\n",
        "\n",
        "2. Variables often need transformation before being included in models:\n",
        "   - Log and polynomial transformations\n",
        "   - Encoding (converting non-numeric features to numeric)\n",
        "   - Scaling (adjusting numeric data to comparable scales)\n",
        "\n",
        "3. Encoding methods depend on the feature type:\n",
        "   - For nominal data (no inherent order):\n",
        "     - Binary encoding (for two-value variables)\n",
        "     - One-hot encoding (for multiple-value variables)\n",
        "   - For ordinal data (inherent order):\n",
        "     - Ordinal encoding\n",
        "\n",
        "4. Binary encoding:\n",
        "   - Converts variables to 0 or 1\n",
        "   - Suitable for true/false or two-option variables\n",
        "\n",
        "5. One-hot encoding:\n",
        "   - Creates multiple binary columns, one for each category\n",
        "   - Used for variables with multiple possible values\n",
        "\n",
        "6. Ordinal encoding:\n",
        "   - Converts ordered categories to numerical values\n",
        "   - Usually uses integers (e.g., low=1, medium=2, high=3)\n",
        "   - Consider if the distance between categories is meaningful\n",
        "\n",
        "The choice of encoding method depends on the data type and the importance of preserving order in categorical variables. Practitioners should consider these factors when preparing data for modeling."
      ],
      "metadata": {
        "id": "HyzBxvdor-dr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling : Variable selection involves choosing the set of features to include in a model, often requiring transformation before inclusion. These transformations include:\n",
        "\n",
        "Log and Polynomial Transformations:\n",
        "\n",
        "Used to adjust the distribution and relationship of data.\n",
        "Encoding:\n",
        "\n",
        "Converts non-numeric features (categorical or ordinal) to numeric features.\n",
        "Binary Encoding: Converts variables with two possible values to 0 or 1 (e.g., male/female).\n",
        "One-Hot Encoding: Converts variables with multiple values into multiple binary columns. For example, a \"color\" column with values \"red,\" \"blue,\" and \"green\" is converted into three columns: \"red,\" \"blue,\" and \"green,\" with binary indicators.\n",
        "Ordinal Encoding: Converts ordered categories into numerical values (e.g., \"low,\" \"medium,\" \"high\" to 1, 2, 3). This assigns a set distance between categories, which may not always be appropriate.\n",
        "Scaling:\n",
        "\n",
        "Adjusts the scale of numeric data to make features comparable.\n",
        "The appropriate method of encoding and scaling depends on the type of feature. For example, nominal data (without inherent order) like colors are suited for one-hot encoding, while ordinal data (with inherent order) like temperature levels can be ordinally encoded.\n",
        "\n",
        "Encoding Methods:\n",
        "Binary Encoding:\n",
        "Suitable for variables with two possible values.\n",
        "Example: Gender (male/female), Married (yes/no).\n",
        "One-Hot Encoding:\n",
        "Suitable for variables with multiple categories.\n",
        "Example: Color (red/blue/green).\n",
        "Ordinal Encoding:\n",
        "Suitable for ordered categories.\n",
        "Example: Satisfaction level (low/medium/high).\n",
        "Key Points:\n",
        "Log and polynomial transformations help in adjusting data distribution.\n",
        "Encoding is crucial for transforming categorical data to numeric.\n",
        "Scaling ensures numeric data is on a comparable scale.\n",
        "The choice of encoding method depends on whether the categorical data has an inherent order or not."
      ],
      "metadata": {
        "id": "S8ahnZDy2jXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformations Based on Feature Type\n",
        "Continuous Numerical Values:\n",
        "\n",
        "Transformations: Standard Scaling, Min-Max Scaling, and Robust Scaling.\n",
        "Python Implementation:\n",
        "Use StandardScaler for standard scaling.\n",
        "Use MinMaxScaler for Min-Max scaling.\n",
        "Use RobustScaler for robust scaling.\n",
        "Nominal or Categorical Data (Unordered):\n",
        "\n",
        "Example: True/False, Red/Blue/Green.\n",
        "Transformations:\n",
        "Binary encoding for features with only two values.\n",
        "One-hot encoding for features with multiple values.\n",
        "Python Implementation:\n",
        "Use LabelEncoder, LabelBinarizer, and OneHotEncoder from sklearn.\n",
        "Use get_dummies from pandas for one-hot encoding.\n",
        "Ordinal Data (Ordered Categorical Data):\n",
        "\n",
        "Example: Low/Medium/High.\n",
        "Transformations:\n",
        "Encode with numbers representing the order (e.g., 1, 2, 3).\n",
        "Python Implementation:\n",
        "Use DictVectorizer to assign numbers to different values.\n",
        "Use OrdinalEncoder to pass in the names of values in the correct order."
      ],
      "metadata": {
        "id": "qPVjuzFf4__7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________"
      ],
      "metadata": {
        "id": "KfE-qLjA7nuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inferential statistics and hypothesis testing are two types of data analysis often overlooked at early stages of analyzing your data. They can give you quick insights about the quality of your data. They also help you confirm business intuition and help you prescribe what to analyze next using Machine Learning. This module looks at useful definitions and simple examples that will help you get started creating hypothesis around your business problem and how to test them.\n",
        "\n",
        "Learning Objectives\n",
        "\n",
        "Understand statistical estimation and inference\n",
        "\n",
        "\n",
        "Recognize parametric and non-parametric approaches to modeling\n",
        "\n",
        "\n",
        "Become familiarized with the most common statistical distributions\n",
        "\n",
        "\n",
        "Fundamental understanding of frequentist vs. Bayesian statistics\n",
        "\n",
        "\n",
        "Hands-on experience communicating insights to peers and stakeholders\n",
        "\n",
        "\n",
        "Hands-on experience providing insights from data\n",
        "\n",
        "\n",
        "Hands-on experience assessing the quality of data\n",
        "\n",
        "\n",
        "Hands-on experience on Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "nSNcSO1UCA8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  This paragraph introduces a section on basic statistical concepts that are important for machine learning and data-driven decision making. Here's a breakdown of the key points:\n",
        "\n",
        "Learning goals for the section:\n",
        "\n",
        "Understanding estimation vs. inference in statistics\n",
        "Differentiating between parametric and non-parametric modeling approaches\n",
        "Exploring common statistical distributions\n",
        "Introducing frequentist vs. Bayesian statistics\n",
        "\n",
        "\n",
        "Estimation vs. Inference:\n",
        "\n",
        "Estimation: Provides an estimate of a parameter (e.g., mean) from sample data\n",
        "Inference: Aims to understand the underlying population distribution, including estimates and other parameters like standard error\n",
        "\n",
        "\n",
        "Relationship between machine learning and statistical inference:\n",
        "\n",
        "Both use sample data to infer qualities of the underlying population distribution\n",
        "Machine learning may focus on the entire distribution or specific features\n",
        "Some ML models emphasize understanding underlying parameters, while others focus more on prediction results\n",
        "\n",
        "\n",
        "Business example: Customer churn prediction\n",
        "\n",
        "Target variable: Whether a customer has left the company\n",
        "Features: Customer tenure, purchase history, age, location, etc.\n",
        "Prediction: Probability of a customer leaving (e.g., 0.99 likely to leave, 0.01 likely to stay)\n",
        "\n",
        "\n",
        "Estimation vs. Inference in the churn example:\n",
        "\n",
        "Estimation: Calculating the impact of each feature (e.g., each additional year as a customer reduces churn by 20%)\n",
        "Inference: Providing statistical significance and confidence intervals for estimates (e.g., 95% confidence interval of 19-21% vs. -10% to 50%)\n",
        "\n",
        "\n",
        "\n",
        "The paragraph emphasizes the importance of understanding these statistical concepts for effective machine learning and data analysis in business contexts."
      ],
      "metadata": {
        "id": "q7oUxC3ACrs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimation and Inference:\n",
        "\n",
        "Here's a summary of the key points from the customer churn data analysis, including relevant code snippets:\n",
        "\n",
        "1. Dataset: Telco customer churn dataset from IBM Cognos Analytics\n",
        "   - Stored in a Pandas DataFrame called `df_phone`\n",
        "\n",
        "2. Bar plot of churn value by payment type:\n",
        "```python\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.barplot(x='payment', y='churn_value', data=df_phone, ci=None)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "3. Bar plot of churn value by tenure (months):\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df_phone['tenure_bins'] = pd.cut(df_phone['tenure_months'], bins=5)\n",
        "sns.barplot(x='tenure_bins', y='churn_value', data=df_phone, ci=None)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "4. Pair plot for multiple features:\n",
        "```python\n",
        "selected_features = ['tenure_months', 'gb_used_per_month', 'total_revenue', 'cltv', 'churn_value']\n",
        "sns.pairplot(df_phone[selected_features], hue='churn_value')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "5. Hexbin plot for tenure vs. monthly charge:\n",
        "```python\n",
        "sns.jointplot(x='tenure_months', y='monthly_charge', data=df_phone, kind='hex')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Key observations:\n",
        "- Credit card users are less likely to churn compared to bank withdrawal or mailed check users.\n",
        "- Customers with shorter tenures are more likely to churn.\n",
        "- The pair plot shows relationships between multiple variables and their distributions, split by churn status.\n",
        "- The hexbin plot reveals density patterns in the relationship between tenure and monthly charges.\n",
        "\n",
        "These visualizations provide insights into factors affecting customer churn, which can be used for further analysis and decision-making in customer retention strategies."
      ],
      "metadata": {
        "id": "ypnXu1JRFtsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimation and Inference - Parametric vs. Non-Parametric:(REVISE)\n",
        "\n",
        "This text discusses parametric and non-parametric statistical models, their characteristics, and common probability distributions. Here's a summary of the key points:\n",
        "\n",
        "1. Parametric vs. Non-parametric Models:\n",
        "   - Parametric models have a finite number of parameters and make strict assumptions about data distributions.\n",
        "   - Non-parametric models rely on fewer assumptions and are distribution-free.\n",
        "\n",
        "2. Examples:\n",
        "   - Non-parametric: Histograms for creating data distributions\n",
        "   - Parametric: Normal distribution with mean and standard deviation parameters\n",
        "\n",
        "3. Maximum Likelihood Estimation (MLE):\n",
        "   - Common method for estimating parameters in parametric models\n",
        "   - Maximizes the likelihood function based on observed data\n",
        "\n",
        "4. Common Probability Distributions:\n",
        "   - Uniform: Equal probability for all values in a range\n",
        "   - Normal (Gaussian): Bell-shaped curve, defined by mean and standard deviation\n",
        "   - Log-normal: Log transformation yields a normal distribution\n",
        "   - Exponential: Models time between events\n",
        "   - Poisson: Models number of events in a fixed time interval\n",
        "\n",
        "5. Central Limit Theorem:\n",
        "   - Averages of multiple samples tend to follow a normal distribution\n",
        "\n",
        "6. Real-world applications:\n",
        "   - Customer Lifetime Value estimation\n",
        "   - Height distributions\n",
        "   - Income distributions\n",
        "   - Video viewing patterns\n",
        "\n",
        "The text emphasizes the importance of understanding these concepts for statistical modeling and data analysis in various fields.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8H3iV57CH4Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Response', y='Annual_Premium', data=data)\n",
        "plt.ylabel(\"Annual_Premium\")\n",
        "plt.xlabel(\"Response\")\n",
        "plt.title(\"Response vs Annual_Premium\")"
      ],
      "metadata": {
        "id": "ZBYQo4ROIi-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final"
      ],
      "metadata": {
        "id": "OAkoEJi6L9W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "wSTUV_02O4F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ohe = pd.get_dummies(data, columns=['Gender','Vehicle_Age','Vehicle_Damage'])"
      ],
      "metadata": {
        "id": "N_G7Ews-Ixdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ohe.shape"
      ],
      "metadata": {
        "id": "QqVyRpEYOkcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "X = data_ohe.drop('Response', axis=1)\n",
        "y = data_ohe['Response']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Training Features:\\n\", X_train)\n",
        "print(\"Test Features:\\n\", X_test)\n",
        "print(\"Training Target:\\n\", y_train)\n",
        "print(\"Test Target:\\n\", y_test)\n"
      ],
      "metadata": {
        "id": "Safu3QPRMCos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Logistic Regression Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "Xa2jHNEFMjTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create and train the model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Decision Tree Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "KuHnFCoDP153"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create and train the model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Random Forest Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "Hz6U-7OJQvkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "\n",
        "# Create and train the model\n",
        "model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'XGBoost Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "nQQo7yIlRG4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create and train the model\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'SVM Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "VmbVwmZZRJk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install psutil\n",
        "import psutil\n",
        "\n",
        "# Number of physical cores\n",
        "physical_cores = psutil.cpu_count(logical=False)\n",
        "\n",
        "# Number of logical cores\n",
        "logical_cores = psutil.cpu_count(logical=True)\n",
        "\n",
        "# CPU frequency\n",
        "cpu_freq = psutil.cpu_freq()\n",
        "\n",
        "# CPU utilization percentage\n",
        "cpu_percent = psutil.cpu_percent(interval=1)\n",
        "\n",
        "# Print CPU specifications\n",
        "print(f\"Physical cores: {physical_cores}\")\n",
        "print(f\"Logical cores: {logical_cores}\")\n",
        "print(f\"Max Frequency: {cpu_freq.max:.2f}Mhz\")\n",
        "print(f\"Min Frequency: {cpu_freq.min:.2f}Mhz\")\n",
        "print(f\"Current Frequency: {cpu_freq.current:.2f}Mhz\")\n",
        "print(f\"CPU Utilization: {cpu_percent}%\")\n",
        "\n",
        "# Per-core utilization\n",
        "print(\"Per-core utilization:\")\n",
        "for i, percentage in enumerate(psutil.cpu_percent(percpu=True, interval=1)):\n",
        "    print(f\"Core {i}: {percentage}%\")\n"
      ],
      "metadata": {
        "id": "KkgJ_Og6ROIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkw_U9eyGLgO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}